{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e2530a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [69, 1378]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2120\\2771743384.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#splitting the dataset into training and testing set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_ts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_ts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#feature scaling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2415\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2417\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [69, 1378]"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jun 29 16:02:29 2018\n",
    "\n",
    "@author: sintu\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import openpyxl\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Dataset\n",
    "xx = pd.read_excel('Top_seven_features.xlsx',sheet_name = 'EngagingTone')\n",
    "x = xx.iloc[:,0:]\n",
    "ym = pd.read_excel('turker_scores.xlsx')\n",
    "y = ym.iloc[0:,12:13]\n",
    "\n",
    "#splitting the dataset into training and testing set\n",
    "x_tr,x_ts,y_tr,y_ts = train_test_split(x,y,test_size=0.1)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "x_tr = sc_X.fit_transform(x_tr)\n",
    "x_ts = sc_X.transform(x_ts)\n",
    "y_tr = sc_y.fit_transform(y_tr)\n",
    "y_ts = sc_y.fit_transform(y_ts)\n",
    "\n",
    "#SVR algorithm for training purpose\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel='rbf')\n",
    "regressor.fit(x_tr,y_tr)\n",
    "\n",
    "#SVR algorithm for testing purpose\n",
    "y_pred = regressor.predict(x_ts)\n",
    "regressor.score(x_tr,y_tr)\n",
    "regressor.score(x_ts,y_ts)\n",
    "\n",
    "#Applying K-Folf cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = regressor, X = x_tr, y = y_tr, cv = 5)\n",
    "accuracies.mean()\n",
    "accuracies.std()\n",
    "\n",
    "#Random forest for training \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor1 = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "regressor1.fit(x_tr,y_tr)\n",
    "\n",
    "#Random forest for testing purpose and predicting score\n",
    "y_pred = regressor.predict(x_ts)\n",
    "regressor1.score(x_tr,y_tr)\n",
    "regressor1.score(x_ts,y_ts)\n",
    "\n",
    "#Applying K-Folf cross validation on random forest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies1 = cross_val_score(estimator = regressor1, X = x_tr, y = y_tr, cv = 5)\n",
    "accuracies1.mean()\n",
    "accuracies1.std()\n",
    "\n",
    "#saving score to the sheet\n",
    "import openpyxl\n",
    "ws = openpyxl.load_workbook('Top_seven_features.xlsx')\n",
    "sheet = ws.get_sheet_by_name('EngagingTone')\n",
    "sheet.cell(row=141,column=1,value = 'SVR')\n",
    "sheet.cell(row=142,column=1,value = 'SVR-->5 values of accuracy by K fold CV')\n",
    "for i in range(2,7):\n",
    "    sheet.cell(row=142,column=i,value =accuracies[i-2])\n",
    "sheet.cell(row=143,column=1,value = 'MeanAccuracies')\n",
    "sheet.cell(row=143,column=2,value =accuracies.mean())\n",
    "sheet.cell(row=144,column=1,value = 'StdAccuracies')\n",
    "sheet.cell(row=144,column=2,value =accuracies.std())\n",
    "sheet.cell(row=146,column=1,value = 'Random Forest')\n",
    "sheet.cell(row=147,column=1,value = 'RForest-->5 values of accuracy by K fold CV')\n",
    "for j in range(2,7):\n",
    "    sheet.cell(row=147,column=j,value =accuracies1[j-2])\n",
    "sheet.cell(row=148,column=1,value = 'MeanAccuracies')\n",
    "sheet.cell(row=148,column=2,value =accuracies1.mean())\n",
    "sheet.cell(row=149,column=1,value = 'StdAccuracies')\n",
    "sheet.cell(row=149,column=2,value =accuracies1.std())\n",
    "ws.save('Top_seven_features.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ceb57d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jun 25 15:32:23 2018\n",
    "\n",
    "@author: sintu\n",
    "\"\"\"\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "def bubbleSort(arr,arr2):\n",
    "    n = len(arr)\n",
    "    for i in range(0,n):\n",
    "        for j in range(0, n-i-1):\n",
    "            if arr[j] < arr[j+1] :\n",
    "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
    "                arr2[j], arr2[j+1] = arr2[j+1], arr2[j]\n",
    "\n",
    "ws = openpyxl.load_workbook('MI_score.xlsx')\n",
    "sheet = ws['Mutual Information']\n",
    "\n",
    "ws1 = openpyxl.load_workbook('features.xlsx')\n",
    "sheet1 = ws1['Feature']\n",
    "\n",
    "from openpyxl import Workbook\n",
    "wb = Workbook()\n",
    "\n",
    "#target = wb.copy_worksheet(sheet)\n",
    "\n",
    "row_count = sheet.max_row\n",
    "column_count = sheet.max_column\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,20):\n",
    "    m = i+1\n",
    "    index =[]\n",
    "    for q in range(1,column_count):\n",
    "        index.append(q)\n",
    "    listx = []\n",
    "    for j in range(1,column_count):\n",
    "        listx.append(sheet.cell(row=m,column=j+1).value)\n",
    "    bubbleSort(listx,index)\n",
    "\n",
    "#Extracting pearsonality traits and naming it to sheet\n",
    "    str = sheet.cell(row=m,column=1).value\n",
    "    wx = wb.create_sheet(str)\n",
    "    \n",
    "#writing person name in !st column of each sheet\n",
    "    for k in range(1,70):\n",
    "        wx.cell(row = k+1,column=1,value = sheet1.cell(row=k+1,column=1).value)\n",
    "\n",
    "#Appending the top 7 feature in 7 list \n",
    "    list = []\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    list3 = []\n",
    "    list4 = []\n",
    "    list5 = []\n",
    "    list6 = []\n",
    "    for p in range(1,71):\n",
    "        list.append(sheet1.cell(row=p,column=index[0]+1).value)\n",
    "        list1.append(sheet1.cell(row=p,column=index[1]+1).value)\n",
    "        list2.append(sheet1.cell(row=p,column=index[2]+1).value)\n",
    "        list3.append(sheet1.cell(row=p,column=index[3]+1).value)\n",
    "        list4.append(sheet1.cell(row=p,column=index[4]+1).value)\n",
    "        list5.append(sheet1.cell(row=p,column=index[5]+1).value)\n",
    "        list6.append(sheet1.cell(row=p,column=index[6]+1).value)\n",
    "\n",
    "\n",
    "#writing in sheet means making top 7 feature for each personality traits    \n",
    "    for j in range(0,70):\n",
    "        wx.cell(row=j+1,column=2,value=list[j])\n",
    "    \n",
    "    for j in range(0,70):\n",
    "        wx.cell(row=j+1,column=3,value=list1[j])\n",
    "    \n",
    "    for j in range(0,70):\n",
    "        wx.cell(row=j+1,column=4,value=list2[j])\n",
    "    \n",
    "    for j in range(0,70):\n",
    "        wx.cell(row=j+1,column=5,value=list3[j])\n",
    "    \n",
    "    for j in range(0,70):\n",
    "        wx.cell(row=j+1,column=6,value=list4[j])\n",
    "    \n",
    "    for j in range(0,70):\n",
    "        wx.cell(row=j+1,column=7,value=list5[j])\n",
    "    \n",
    "    for j in range(0,70):\n",
    "        wx.cell(row=j+1,column=8,value=list6[j])\n",
    "            \n",
    "#saving the top seven feature for each traits in a file       \n",
    "wb.save('Top_seven_features.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c4f2ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    work   I  Verb  Preposition  Negations  Quqntifier  NegEmotion\n",
      "0      4  17    65           38          0           0           0\n",
      "1      4  27    89           46          0           0           0\n",
      "2      1  11    40           27          0           0           0\n",
      "3      6   6    65           47          0           0           0\n",
      "4      3  12    63           44          0           0           0\n",
      "..   ...  ..   ...          ...        ...         ...         ...\n",
      "64     1   6    37           16          0           0           0\n",
      "65     0  18    95           53          2           0           0\n",
      "66     5  17    77           60          0           0           0\n",
      "67     3  24   112           59          0           0           0\n",
      "68     1  13    39           30          1           0           0\n",
      "\n",
      "[69 rows x 7 columns] hey\n",
      "    EngagingTone\n",
      "0       5.147909\n",
      "1       5.621231\n",
      "2       4.392736\n",
      "3       4.695523\n",
      "4       4.261988\n",
      "..           ...\n",
      "64      5.912896\n",
      "65      6.076712\n",
      "66      4.188872\n",
      "67      5.356061\n",
      "68      4.617294\n",
      "\n",
      "[69 rows x 1 columns] hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhanya\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Dhanya\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Dhanya\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Dhanya\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Dhanya\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Dhanya\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Dhanya\\AppData\\Local\\Temp\\ipykernel_2120\\667413583.py:55: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor1.fit(x_tr,y_tr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    work   I  Verb  Preposition  Negations  Quqntifier  NegEmotion\n",
      "59     0   9    25           15          0           0           0\n",
      "22     3  15    47           35          1           0           0\n",
      "44     2  11    55           50          0           0           0\n",
      "18     7  15   107           79          1           0           0\n",
      "64     1   6    37           16          0           0           0\n",
      "..   ...  ..   ...          ...        ...         ...         ...\n",
      "38     3  22    86           72          0           0           0\n",
      "41     3  18    71           25          0           0           0\n",
      "14     6   3    40           31          0           0           0\n",
      "63     0  19    68           38          0           0           0\n",
      "66     5  17    77           60          0           0           0\n",
      "\n",
      "[62 rows x 7 columns] Training     work   I  Verb  Preposition  Negations  Quqntifier  NegEmotion\n",
      "36     3   4    37           27          0           0           0\n",
      "12     0  14    75           71          0           0           0\n",
      "24     2  11    54           64          0           0           0\n",
      "29     1   8    22           17          0           0           0\n",
      "6      0  17    98           79          1           0           0\n",
      "61     8   9    51           37          0           0           0\n",
      "28     0  13    99           64          0           0           0 Testing     EngagingTone\n",
      "59      5.044032\n",
      "22      2.304304\n",
      "44      5.409835\n",
      "18      5.914143\n",
      "64      5.912896\n",
      "..           ...\n",
      "38      4.854321\n",
      "41      6.279074\n",
      "14      4.752225\n",
      "63      5.211161\n",
      "66      4.188872\n",
      "\n",
      "[62 rows x 1 columns] training     EngagingTone\n",
      "36      4.395978\n",
      "12      4.378983\n",
      "24      5.982118\n",
      "29      5.337047\n",
      "6       4.157069\n",
      "61      5.033576\n",
      "28      5.552795 Testing\n",
      "[4.84264235 4.57236562 4.40244385 4.91022344 4.78097982 4.76611089\n",
      " 4.99435676] hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhanya\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Dhanya\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Dhanya\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Dhanya\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\Dhanya\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.13822688 -0.27948848 -1.20862436 -1.16997855 -0.45118324] Accuracies\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jun 29 16:02:29 2018\n",
    "\n",
    "@author: sintu\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import openpyxl\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Dataset\n",
    "xx = pd.read_excel('Top1.xlsx',sheet_name = 'EngagingTone')\n",
    "x = xx.iloc[:,1:]\n",
    "ym = pd.read_excel('turker_scores_3.xlsx')\n",
    "y = ym.iloc[0:,11:12]\n",
    "\n",
    "print(x,\"hey\")\n",
    "print(y,\"hey\")\n",
    "#splitting the dataset into training and testing set\n",
    "x_tr,x_ts,y_tr,y_ts = train_test_split(x,y,test_size=0.1)\n",
    "\n",
    "#feature scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc_X = StandardScaler()\n",
    "# sc_y = StandardScaler()\n",
    "# x_tr = sc_X.fit_transform(x_tr)\n",
    "# x_ts = sc_X.transform(x_ts)\n",
    "# y_tr = sc_y.fit_transform(y_tr)\n",
    "# y_ts = sc_y.fit_transform(y_ts)\n",
    "\n",
    "#SVR algorithm for training purpose\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel='rbf')\n",
    "regressor.fit(x_tr,y_tr)\n",
    "\n",
    "#SVR algorithm for testing purpose\n",
    "\n",
    "y_pred = regressor.predict(x_ts)\n",
    "regressor.score(x_tr,y_tr)\n",
    "regressor.score(x_ts,y_ts)\n",
    "\n",
    "#Applying K-Folf cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = regressor, X = x_tr, y = y_tr, cv = 5)\n",
    "accuracies.mean()\n",
    "accuracies.std()\n",
    "\n",
    "#Random forest for training \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor1 = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "regressor1.fit(x_tr,y_tr)\n",
    "\n",
    "#Random forest for testing purpose and predicting score\n",
    "print(x_tr, \"Training\",x_ts,\"Testing\",y_tr,\"training\",y_ts,\"Testing\")\n",
    "y_pred = regressor.predict(x_ts)\n",
    "print(y_pred,\"hello\")\n",
    "sc1=regressor1.score(x_tr,y_tr)\n",
    "sc2=regressor1.score(x_ts,y_ts)\n",
    "#print(sc1,sc2,\"Score :\")\n",
    "\n",
    "#Applying K-Folf cross validation on random forest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies1 = cross_val_score(estimator = regressor1, X = x_tr, y = y_tr, cv = 5)\n",
    "print(accuracies1,\"Accuracies\")\n",
    "accuracies1.mean()\n",
    "accuracies1.std()\n",
    "\n",
    "#saving score to the sheet\n",
    "# import openpyxl\n",
    "ws = openpyxl.load_workbook('Top1.xlsx')\n",
    "sheet = ws['EngagingTone']\n",
    "next_column = sheet.max_column + 1\n",
    "row_num=64\n",
    "j=0\n",
    "for i in range(64,sheet.max_row+1):\n",
    "    sheet.cell(row=i,column=next_column,value=y_pred[j]*10)\n",
    "    j=j+1\n",
    "# sheet.cell(row=141,column=1,value = 'SVR')\n",
    "# sheet.cell(row=142,column=1,value = 'SVR-->5 values of accuracy by K fold CV')\n",
    "# for i in range(2,7):\n",
    "#     sheet.cell(row=142,column=i,value =accuracies[i-2])\n",
    "# sheet.cell(row=143,column=1,value = 'MeanAccuracies')\n",
    "# sheet.cell(row=143,column=2,value =accuracies.mean())\n",
    "# sheet.cell(row=144,column=1,value = 'StdAccuracies')\n",
    "# sheet.cell(row=144,column=2,value =accuracies.std())\n",
    "# sheet.cell(row=146,column=1,value = 'Random Forest')\n",
    "# sheet.cell(row=147,column=1,value = 'RForest-->5 values of accuracy by K fold CV')\n",
    "# for j in range(2,7):\n",
    "#     sheet.cell(row=147,column=j,value =accuracies1[j-2])\n",
    "# sheet.cell(row=148,column=1,value = 'MeanAccuracies')\n",
    "# sheet.cell(row=148,column=2,value =accuracies1.mean())\n",
    "# sheet.cell(row=149,column=1,value = 'StdAccuracies')\n",
    "# sheet.cell(row=149,column=2,value =accuracies1.std())\n",
    "ws.save('Top1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5456b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('lexical_features.csv')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1], data.iloc[:, -1], test_size=0.2, random_state=42)\n",
    "\n",
    "# Select the most relevant features using mutual information\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "selector = SelectKBest(mutual_info_classif, k=10)\n",
    "selector.fit(X_train, y_train)\n",
    "X_train = selector.transform(X_train)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# Train a random forest model on the selected features\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the testing set\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2 score: {r2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
